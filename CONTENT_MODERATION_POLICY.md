# ðŸ”’ Atlas Content Moderation Policy

**Last Updated:** November 14, 2025  
**Status:** âœ… Active

---

## ðŸ“‹ **OVERVIEW**

Atlas implements a multi-layer content moderation system to ensure a safe, respectful environment for all users. This document outlines our moderation approach, tools, and audit processes.

---

## ðŸ›¡ï¸ **MULTI-LAYER MODERATION STRATEGY**

### **Layer 1: Pre-Processing (User Input Screening)**
- **Tool:** OpenAI Moderation API
- **Purpose:** Screen user messages before sending to AI
- **Coverage:** Sexual content, hate speech, harassment, self-harm, violence
- **Action:** High-confidence violations (>0.9) are automatically blocked
- **Cost:** ~$0.0001 per 1,000 characters (negligible)

### **Layer 2: AI Model Safety (Built-in)**
- **Tool:** Anthropic Claude Safety Filters
- **Purpose:** Filter harmful AI responses automatically
- **Coverage:** Built into Claude API (no additional cost)
- **Action:** Automatic filtering of unsafe responses

### **Layer 3: Post-Processing (Response Filtering)**
- **Tool:** Response filtering system
- **Purpose:** Clean up branding and stage directions
- **Status:** âœ… Already implemented

### **Layer 4: User Reporting (Community-Driven)**
- **Tool:** User reporting mechanism
- **Purpose:** Allow users to flag inappropriate content
- **Action:** Reports reviewed by admin team
- **Status:** âœ… Implemented

---

## ðŸš¨ **HANDLING FLAGGED CONTENT**

### **High-Confidence Violations (>0.9)**
- **Action:** Automatic block
- **User Message:** "Your message couldn't be processed. Please rephrase your message to continue."
- **Logging:** All blocks logged in `moderation_logs` table

### **Medium-Confidence Violations (0.5-0.9)**
- **Action:** Allowed but logged for manual review
- **Review:** Monthly audit process
- **Logging:** Flagged in `moderation_logs` table

### **Low-Confidence Violations (<0.5)**
- **Action:** Allowed with monitoring
- **Logging:** Tracked for trend analysis

---

## ðŸ“Š **AUDIT PROCESS**

### **Monthly Audits**
- **Frequency:** First Monday of each month
- **Scope:** Review all flagged content from previous month
- **Actions:**
  - Review high-confidence blocks for false positives
  - Review medium-confidence violations for policy updates
  - Analyze trends and patterns
  - Update moderation rules if needed

### **Quarterly Policy Reviews**
- **Frequency:** Every 3 months
- **Scope:** Review moderation policies and effectiveness
- **Actions:**
  - Update content guidelines
  - Adjust confidence thresholds if needed
  - Review user feedback and reports
  - Update Terms of Service if needed

### **Annual Compliance Check**
- **Frequency:** Once per year
- **Scope:** Full compliance verification
- **Actions:**
  - Verify all moderation systems working
  - Review audit logs completeness
  - Update documentation
  - Compliance report generation

---

## ðŸ”§ **MODERATION TOOLS**

### **Primary Tool: OpenAI Moderation API**
- **Provider:** OpenAI
- **Accuracy:** 99%+ for explicit content
- **Speed:** <100ms response time
- **Cost:** ~$0.0001 per 1,000 characters
- **Coverage:**
  - Sexual content
  - Hate speech
  - Harassment
  - Self-harm
  - Violence
  - Sexual/minors
  - Hate/threatening
  - Violence/graphic

### **Secondary Tool: Anthropic Claude Safety Filters**
- **Provider:** Anthropic
- **Type:** Built into Claude API
- **Cost:** No additional cost
- **Coverage:** Automatic filtering of harmful responses

---

## ðŸ“ **USER REPORTING**

### **How to Report**
Users can report inappropriate content through:
- Report button on messages (to be added to UI)
- API endpoint: `POST /api/report-content`

### **Report Reasons**
- Inappropriate content
- Harassment
- Spam
- Violence
- Self-harm
- Other

### **Report Processing**
1. Report created in `content_reports` table
2. Status: `pending`
3. Admin review (within 48 hours)
4. Status updated: `reviewed`, `resolved`, or `dismissed`

---

## ðŸ“ˆ **METRICS & MONITORING**

### **Key Metrics Tracked**
- Total moderation checks
- Flagged content rate
- Blocked content rate
- False positive rate
- User reports submitted
- Average response time

### **Monitoring Dashboard**
- Real-time moderation stats
- Trend analysis
- Alert thresholds

---

## ðŸ” **DATA RETENTION**

### **Moderation Logs**
- **Retention:** 12 months
- **Purpose:** Audit trail and compliance
- **Storage:** Supabase `moderation_logs` table

### **Content Reports**
- **Retention:** 12 months
- **Purpose:** Review and appeals
- **Storage:** Supabase `content_reports` table

---

## âœ… **COMPLIANCE**

### **App Store Requirements**
- âœ… Content moderation system in place
- âœ… Clear content policies (Terms of Service)
- âœ… User reporting mechanism
- âœ… Regular audits documented

### **Industry Standards**
- âœ… Multi-layer defense strategy
- âœ… Automated detection + manual review
- âœ… Regular policy updates
- âœ… Transparent user communication

---

## ðŸ“ž **CONTACT**

For questions about content moderation:
- Email: support@atlas.ai
- Report inappropriate content: Use in-app reporting mechanism

---

**Status:** âœ… **Active - Pre-Launch Implementation Complete**

